#include <stdio.h>
#include <stdlib.h>
#include <math.h>

float TRAIN_DATA[][3] = {
    {0, 0, 0},
    {0, 1, 1},
    {1, 0, 1},
    {1, 1, 0}
};
#define TRAIN_COUNT (sizeof(TRAIN_DATA) / sizeof(TRAIN_DATA[0]))

float sigmoid(float x) {
    return 1.f / (1.f + expf(-x));
}

float rand_float(void) {
    return (float)rand() / (float)RAND_MAX;
}

// Modello a 3 neuroni
float model_cost(float w1[3], float w2[3], float b[3], float v[3], float vb) {
    float cost = 0.0f;
    for (int i = 0; i < TRAIN_COUNT; i++) {
        float x1 = TRAIN_DATA[i][0];
        float x2 = TRAIN_DATA[i][1];
        float y_expected = TRAIN_DATA[i][2];

        // Layer nascosto (3 neuroni)
        float z1 = sigmoid(w1[0] * x1 + w2[0] * x2 + b[0]);
        float z2 = sigmoid(w1[1] * x1 + w2[1] * x2 + b[1]);
        float z3 = sigmoid(w1[2] * x1 + w2[2] * x2 + b[2]);

        // Output layer
        float y_computed = sigmoid(v[0] * z1 + v[1] * z2 + v[2] * z3 + vb);

        float d = y_computed - y_expected;
        cost += d * d;
    }
    cost /= TRAIN_COUNT;
    return cost;
}

int main(void) {
    srand(1337);

    // Inizializzazione pesi e bias per 3 neuroni nel layer nascosto
    float w1[3] = {rand_float() * 5.f, rand_float() * 5.f, rand_float() * 5.f};
    float w2[3] = {rand_float() * 10.f, rand_float() * 10.f, rand_float() * 10.f};
    float b[3] = {rand_float() * 5.f, rand_float() * 5.f, rand_float() * 5.f};
    float v[3] = {rand_float() * 5.f, rand_float() * 5.f, rand_float() * 5.f};
    float vb = rand_float() * 5.f;

    // Parametri di training
    float learning_rate = 2;
    float eps = 1e-3;
    float epochs = 100000;

    // Training del modello
    for (size_t i = 0; i < epochs; i++) {
        float c = model_cost(w1, w2, b, v, vb);
        float dw1[3], dw2[3], db[3], dv[3], dvb;

        for (int j = 0; j < 3; j++) {
            dw1[j] = (model_cost((float[3]){w1[0] + eps * (j == 0), w1[1] + eps * (j == 1), w1[2] + eps * (j == 2)}, w2, b, v, vb) - c) / eps;
            dw2[j] = (model_cost(w1, (float[3]){w2[0] + eps * (j == 0), w2[1] + eps * (j == 1), w2[2] + eps * (j == 2)}, b, v, vb) - c) / eps;
            db[j] = (model_cost(w1, w2, (float[3]){b[0] + eps * (j == 0), b[1] + eps * (j == 1), b[2] + eps * (j == 2)}, v, vb) - c) / eps;
            dv[j] = (model_cost(w1, w2, b, (float[3]){v[0] + eps * (j == 0), v[1] + eps * (j == 1), v[2] + eps * (j == 2)}, vb) - c) / eps;
        }

        dvb = (model_cost(w1, w2, b, v, vb + eps) - c) / eps;

        for (int j = 0; j < 3; j++) {
            w1[j] -= learning_rate * dw1[j];
            w2[j] -= learning_rate * dw2[j];
            b[j] -= learning_rate * db[j];
            v[j] -= learning_rate * dv[j];
        }
        vb -= learning_rate * dvb;
    }

    // Stampa dei risultati dopo il training
    for (int i = 0; i < TRAIN_COUNT; i++) {
        float x1 = TRAIN_DATA[i][0];
        float x2 = TRAIN_DATA[i][1];
        float y_expected = TRAIN_DATA[i][2];

        // Layer nascosto (3 neuroni)
        float z1 = sigmoid(w1[0] * x1 + w2[0] * x2 + b[0]);
        float z2 = sigmoid(w1[1] * x1 + w2[1] * x2 + b[1]);
        float z3 = sigmoid(w1[2] * x1 + w2[2] * x2 + b[2]);

        // Output layer
        float y_computed = sigmoid(v[0] * z1 + v[1] * z2 + v[2] * z3 + vb);

        printf("%f ^ %f = %f | expected %f\n", x1, x2, y_computed, y_expected);
    }

    return 0;
}
